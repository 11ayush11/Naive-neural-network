{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylab import imread,subplot,imshow,title,gray,figure,show,NullLocator\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import logging\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.image as mping\n",
    "import glob\n",
    "import os\n",
    "from os import path\n",
    "import cv2\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2996, 10000)\n",
      "(333,)\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(\"G:/ml/face datacet/dataset 2/*/*.jpg\") ## location of image dataset \n",
    "X_data = []\n",
    "X_name = []\n",
    "Y_data = []\n",
    "Y_name = []\n",
    "name_int = []\n",
    "x_index = []\n",
    "y_index = []\n",
    "i = 0\n",
    "s = 0\n",
    "p = 0\n",
    "num=0\n",
    "numy = 0\n",
    "for myfile in files:\n",
    "    image = cv2.imread(myfile)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    l,b = gray_image.shape\n",
    "    p = b\n",
    "    resize_image = cv2.resize(gray_image,(100,100))\n",
    "    b = resize_image.ravel()\n",
    "    b = b/255.0\n",
    "    if (i%2==0 and i%20!=0):\n",
    "        X_data.append(b)\n",
    "        s = s+1\n",
    "        a,b =(os.path.split(myfile))\n",
    "        match = re.search(r'\\w+',b)\n",
    "        b = match.group()\n",
    "        X_name.append(b)\n",
    "        num = num+1\n",
    "    if(i%20==0):\n",
    "        Y_data.append(b)\n",
    "        a,b =(os.path.split(myfile))\n",
    "        match = re.search(r'\\w+',b)\n",
    "        b = match.group()\n",
    "        Y_name.append(b)\n",
    "        numy = numy+1\n",
    "    i = i+1  \n",
    "X_data = np.asarray(X_data)\n",
    "Y_data = np.asarray(Y_data)\n",
    "print (np.array(X_data).shape)\n",
    "print (np.array(Y_name).shape)\n",
    "i = 0\n",
    "for name in X_name:\n",
    "    if name in name_int:\n",
    "        x_index.append(name_int.index(name))\n",
    "    else:\n",
    "        name_int.append(name)\n",
    "        x_index.append(name_int.index(name))\n",
    "for name in Y_name:\n",
    "    if name in name_int:\n",
    "        y_index.append(name_int.index(name))\n",
    "    else:\n",
    "        name_int.append(name)\n",
    "        y_index.append(name_int.index(name))\n",
    "x_index = np.asarray(x_index)\n",
    "y_index = np.asarray(y_index)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289\n",
      "(2996, 10000)\n",
      "(333, 10000)\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import shuffle\n",
    "X_train, X_test = shuffle(X_data, x_index, random_state=200)\n",
    "Y_data, Y_name = shuffle(Y_data,y_index, random_state=200)\n",
    "print (X_test[1])\n",
    "print (X_train.shape)\n",
    "print (Y_data.shape)\n",
    "X_train = X_train.reshape((num,100,100,1))\n",
    "Y_data = Y_data.reshape((numy,100,100,1))\n",
    "number_of_classes = 333\n",
    "X_labels = np_utils.to_categorical(X_test, number_of_classes)\n",
    "Y_labels = np_utils.to_categorical(Y_name, number_of_classes)\n",
    "print (X_labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 1/8\n",
      "93/93 [==============================] - 578s 6s/step - loss: 4.5101 - acc: 0.1862 - val_loss: 2.1193 - val_acc: 0.5563\n",
      "Epoch 2/8\n",
      "93/93 [==============================] - 573s 6s/step - loss: 2.1978 - acc: 0.6015 - val_loss: 1.1119 - val_acc: 0.7594\n",
      "Epoch 3/8\n",
      "93/93 [==============================] - 552s 6s/step - loss: 1.2623 - acc: 0.7851 - val_loss: 0.9496 - val_acc: 0.7812\n",
      "Epoch 4/8\n",
      "93/93 [==============================] - 548s 6s/step - loss: 0.7600 - acc: 0.8729 - val_loss: 1.3648 - val_acc: 0.6438\n",
      "Epoch 5/8\n",
      "93/93 [==============================] - 535s 6s/step - loss: 0.4970 - acc: 0.9087 - val_loss: 0.6487 - val_acc: 0.8500\n",
      "Epoch 6/8\n",
      "93/93 [==============================] - 538s 6s/step - loss: 0.3510 - acc: 0.9409 - val_loss: 0.3189 - val_acc: 0.9125\n",
      "Epoch 7/8\n",
      "93/93 [==============================] - 544s 6s/step - loss: 0.2725 - acc: 0.9574 - val_loss: 0.3834 - val_acc: 0.9125\n",
      "Epoch 8/8\n",
      "93/93 [==============================] - 538s 6s/step - loss: 0.2284 - acc: 0.9577 - val_loss: 0.1397 - val_acc: 0.9750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1654e1fffd0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(100,100,1)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(333))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                         height_shift_range=0.08, zoom_range=0.08)\n",
    "print (3)\n",
    "test_gen = ImageDataGenerator()\n",
    "train_generator = gen.flow(X_train, X_labels, batch_size=32)\n",
    "test_generator = test_gen.flow(Y_data, Y_labels, batch_size=32)\n",
    "model.fit_generator(train_generator, steps_per_epoch=num//32, epochs=8, \n",
    "                    validation_data=test_generator, validation_steps=numy//32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
