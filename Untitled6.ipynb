{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylab import imread,subplot,imshow,title,gray,figure,show,NullLocator\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import logging\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.image as mping\n",
    "import glob\n",
    "import os\n",
    "from os import path\n",
    "import cv2\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6324, 10000)\n",
      "(333,)\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(\"G:/ml/face datacet/dataset 2/*/*.jpg\") ## location of image dataset \n",
    "X_data = []\n",
    "X_name = []\n",
    "Y_data = []\n",
    "Y_name = []\n",
    "name_int = []\n",
    "x_index = []\n",
    "y_index = []\n",
    "i = 0\n",
    "s = 0\n",
    "p = 0\n",
    "num=0\n",
    "numy = 0\n",
    "for myfile in files:\n",
    "    image = cv2.imread(myfile)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    l,b = gray_image.shape\n",
    "    p = b\n",
    "    resize_image = cv2.resize(gray_image,(100,100))\n",
    "    b = resize_image.ravel()\n",
    "    b = b/255.0\n",
    "    if (i%20!=0):\n",
    "        X_data.append(b)\n",
    "        s = s+1\n",
    "        a,b =(os.path.split(myfile))\n",
    "        match = re.search(r'\\w+',b)\n",
    "        b = match.group()\n",
    "        X_name.append(b)\n",
    "        num = num+1\n",
    "    if(i%20==0):\n",
    "        Y_data.append(b)\n",
    "        a,b =(os.path.split(myfile))\n",
    "        match = re.search(r'\\w+',b)\n",
    "        b = match.group()\n",
    "        Y_name.append(b)\n",
    "        numy = numy+1\n",
    "    i = i+1  \n",
    "X_data = np.asarray(X_data)\n",
    "Y_data = np.asarray(Y_data)\n",
    "print (np.array(X_data).shape)\n",
    "print (np.array(Y_name).shape)\n",
    "i = 0\n",
    "for name in X_name:\n",
    "    if name in name_int:\n",
    "        x_index.append(name_int.index(name))\n",
    "    else:\n",
    "        name_int.append(name)\n",
    "        x_index.append(name_int.index(name))\n",
    "for name in Y_name:\n",
    "    if name in name_int:\n",
    "        y_index.append(name_int.index(name))\n",
    "    else:\n",
    "        name_int.append(name)\n",
    "        y_index.append(name_int.index(name))\n",
    "x_index = np.asarray(x_index)\n",
    "y_index = np.asarray(y_index)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import shuffle\n",
    "X_train, X_test = shuffle(X_data, x_index, random_state=200)\n",
    "Y_data, Y_name = shuffle(Y_data,y_index, random_state=200)\n",
    "print (X_test[1])\n",
    "X_train = X_train.reshape((num,100,100,1))\n",
    "Y_data = Y_data.reshape((numy,100,100,1))\n",
    "number_of_classes = 333\n",
    "X_labels = np_utils.to_categorical(X_test, number_of_classes)\n",
    "Y_labels = np_utils.to_categorical(Y_name, number_of_classes)\n",
    "print (X_labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 1/7\n",
      "98/98 [==============================] - 1237s 13s/step - loss: 2.7967 - acc: 0.4778 - val_loss: 1.0731 - val_acc: 0.7438\n",
      "Epoch 2/7\n",
      "98/98 [==============================] - 1186s 12s/step - loss: 0.6553 - acc: 0.8801 - val_loss: 0.4553 - val_acc: 0.8844\n",
      "Epoch 3/7\n",
      "98/98 [==============================] - 1167s 12s/step - loss: 0.2934 - acc: 0.9488 - val_loss: 0.3733 - val_acc: 0.8938\n",
      "Epoch 4/7\n",
      "98/98 [==============================] - 1228s 13s/step - loss: 0.1650 - acc: 0.9725 - val_loss: 0.2861 - val_acc: 0.9281\n",
      "Epoch 5/7\n",
      "98/98 [==============================] - 1235s 13s/step - loss: 0.1289 - acc: 0.9755 - val_loss: 0.1040 - val_acc: 0.9781\n",
      "Epoch 6/7\n",
      "98/98 [==============================] - 1233s 13s/step - loss: 0.0836 - acc: 0.9872 - val_loss: 0.0954 - val_acc: 0.9812\n",
      "Epoch 7/7\n",
      "98/98 [==============================] - 1171s 12s/step - loss: 0.0790 - acc: 0.9850 - val_loss: 0.2305 - val_acc: 0.9469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1653aa86e48>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(100,100,1)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(333))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                         height_shift_range=0.08, zoom_range=0.08)\n",
    "print (3)\n",
    "test_gen = ImageDataGenerator()\n",
    "train_generator = gen.flow(X_train, X_labels, batch_size=64)\n",
    "test_generator = test_gen.flow(Y_data, Y_labels, batch_size=64)\n",
    "model.fit_generator(train_generator, steps_per_epoch=num//64, epochs=7, \n",
    "                    validation_data=test_generator, validation_steps=numy//64)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
